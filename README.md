# uLMTutorial
从0到1动手学习大模型技术

## :telescope:目录

### :computer:科普课程

| 科普课程                                                     | 课程描述内容                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [Recent Advances on Foundation Models](https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/) | 滑铁卢大学Wenhu Chen老师的课程“Recent Advances on Foundation Models”在滑铁卢大学是公开的。课程中，覆盖了许多有趣的话题，包括**Transformers、LLM、预训练、量化、稀疏注意力、指令调整、RLHF、提示、视觉Transformers、扩散模型、多模态模型、代理、RAG**等。https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/ |
| [stas00](https://github.com/stas00)/[ml-engineering](https://github.com/stas00/ml-engineering) | 《Machine Learning Engineering Open Book》的开源书籍，该书籍汇集了多种方法论，旨在帮助训练大型语言模型和多模态模型。文章指出，这本书适合用于大型语言模型（LLM）和超大型语言模型（VLM）的培训工程师和操作员，其中包含了许多脚本和复制粘贴命令，以便快速满足需求。文章还提到，这本书是一个持续的脑洞集合，作者在训练开源BLOOM-176B模型和IDEFICS-80B多模态模型时获得了许多专业知识。目前，作者正在Contextual.AI开发/训练开源检索增强模型。文章最后提到了该书籍的目录结构，包括见解、关键硬件组件、性能、操作、开发、杂项等部分。 |
| [langchain/cookbook](https://github.com/langchain-ai/langchain/tree/masterhttps://github.com/langchain-ai/langchain/tree/master/cookbook) | LangChain提供了一个名为cookbook的代码示例集合，可用于构建使用LangChain的应用程序。这个cookbook强调更多应用和端到端示例，而不是主要文档中包含的示例。其中包括一个构建聊天应用程序的示例，该应用程序可以使用开源的llm（llama2）与SQL数据库进行交互，具体示例展示了包含名单的SQLite数据库 |
| [rasbt](https://github.com/rasbt)/[LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) | 如何从零开始构建一个类似于ChatGPT的大型语言模型（LLM）。通过逐步的指导和清晰的文本、图表和例子，引导读者创建自己的LLM。文章还提到了训练和发展自己用于教育目的的小型但功能齐全的模型的方法，这与创建大型基础模型（如ChatGPT）的方法类似。文章还提供了章节标题和主要代码的快速访问链接 |
| [2024年构建大型语言模型的小指南](https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/mobilepresent?pli=1&slide=id.g2c144c77cfe_0_352) | **Hugging Face创始人Thomas Wolf讲解**如何构建大型语言模型的文章。该文章可能提供了关于大型语言模型的定义、预训练过程、技术挑战和伦理关注点等内容。它还可能介绍了Meta AI在2024年推出的大型语言模型，并突出了其性能优势。文章可能还包括关于大型语言模型在自然语言处理和人工智能领域的应用以及构建这类模型所需的专业技能和知识然而，由于上下文提供的信息有限，无法对文章的具体内容进行进一步详细解释 |
| **[Hung-yi Lee GPT科普视频](https://www.youtube.com/@HungyiLeeNTU)**（油管） | **通俗易懂讲解什么chatgpt？什么GenAI,课程生动有趣**          |
| [datawhalechina](https://github.com/datawhalechina)/ [so-large-lm](https://github.com/datawhalechina/so-large-lm) | datawhale构建项目旨在作为一个大规模预训练语言模型的教程，从数据准备、模型构建、训练策略到模型评估与改进，以及模型在安全、隐私、环境和法律道德方面的方面来提供开源知识。 |
| [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/) | 项目将以[斯坦福大学大规模语言模型课程](https://stanford-cs324.github.io/winter2022/)和[李宏毅生成式AI课程](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)为基础，结合来自开源贡献者的补充和完善，以及对前沿大模型知识的及时更新，为读者提供较为全面而深入的理论知识和实践方法。通过对模型构建、训练、评估与改进等方面的系统性讲解，以及代码的实战，我们希望建立一个具有广泛参考价值的项目**从传统的NLP到大模型技术进行全面的讲解，其中包含各种小项目实践操作** |
| **[ Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g)** | **无代码的科普，讲述大模型如何通过算力压缩得到，**[ppt地址](https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view) |
| [mlabonne](https://github.com/mlabonne)/**[llm-course](https://github.com/mlabonne/llm-course)** | 该文章主要介绍了如何通过一个课程进入大型语言模型（LLMs）的学习，该课程分为三个部分：LLM基础、LLM科学家和LLM工程师。课程提供了相关的笔记本和文章，包括用于评估LLMs、合并模型、量化LLMs和其他相关主题的工具和资源，分别提供基础课程以及LLM科学家和工程师技术路线，课程具备了基础知识、理论阐述和项目实践操纵 |
| [microsoft](https://github.com/microsoft)/**[generative-ai-for-beginners](https://github.com/microsoft/generative-ai-for-beginners)** | 主要介绍了一个由微软云倡导者提供的12节课的课程，旨在帮助初学者学习生成式AI应用程序的开发。课程涵盖了生成式AI原理和应用程序开发的关键方面，通过学习，学生可以构建自己的生成式AI初创公司，以了解启动创意所需的条件。文章还提到了如何开始学习、与其他学习者交流和支持、进一步学习资源以及如何为课程做出贡献 |
| [复旦大学-《大规模语言模型：理论到实践》](https://intro-llm.github.io/) | **基本阐述大模型发展历史、技术细节和评估方式** [复旦大学张奇教授相关资料](https://zhuanlan.zhihu.com/p/670742372) |



###  :mag_right:数据收集与分析

### :chart_with_upwards_trend:应用技术

### :ledger:模型基础技术

### :dart:基础平台技术能力
